import cv2 as cv 
import numpy as np
from pyzbar.pyzbar import decode
import pyzbar
import time
import serial
# arduino = serial.Serial('/dev/cu.usbserial-1410', 115200, timeout=1)
time.sleep(2)

def textBGoutline(img, text, position, fonts=cv.FONT_HERSHEY_SIMPLEX ,scaling=1, text_color=(0,255,0), thickness=1, bg_color=(0,0,0)):
    img_h, img_w = img.shape[:2]
    x, y = position
    (w, h ), p= cv.getTextSize(text, fonts, scaling, thickness)
    # print(w, h)
    cv.rectangle(img, (x-p, y+p), (x+w+p, y-h-p), bg_color, -1)
    cv.rectangle(img, (x-p, y+p), (x+w+p, y-h-p), text_color,thickness, cv.LINE_AA)
    
    cv.putText(img, text, position,fonts, scaling,  text_color, thickness, cv.LINE_AA)
def track_speed(prev_frame, current_frame, prev_points):
    # Parameters for Lucas-Kanade optical flow
    lk_params = dict(winSize=(20, 20), maxLevel=4, criteria=(cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.01))
    # Calculate optical flow
    current_points, status, _ = cv.calcOpticalFlowPyrLK(prev_frame, current_frame, prev_points, None, **lk_params)

    # Filter valid points
    valid_current_points = current_points[status.flatten() == 1]
    valid_prev_points = prev_points[status.flatten() == 1]


    # Calculate displacement and speed
    displacement = np.sqrt(np.sum(np.square(valid_current_points - valid_prev_points), axis=1))
    speed = np.mean(displacement)

    return speed, valid_current_points

def fillPolyTrans(img, points, color, opacity, line_thickness=2):
    list_to_np_array = np.array(points, dtype=np.int32)
    overlay = img.copy()  # coping the image
    cv.fillPoly(overlay,[list_to_np_array], color )
    new_img = cv.addWeighted(overlay, opacity, img, 1 - opacity, 0)
    # print(points_list)
    img = new_img
    cv.polylines(img, [list_to_np_array], True, color,line_thickness, cv.LINE_AA)
    return img


# QR code detector function 
def detectQRcode(image):
    # convert the color image to gray scale image
    Gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)

    # create QR code object
    objectQRcode = pyzbar.pyzbar.decode(Gray)
    for obDecoded in objectQRcode: 
        x, y, w, h =obDecoded.rect
        # cv.rectangle(image, (x,y), (x+w, y+h), ORANGE, 4)
        points = obDecoded.polygon
        if len(points) > 4:
            hull = cv.convexHull(
                np.array([points for point in points], dtype=np.float32))
            hull = list(map(tuple, np.squeeze(hull)))
        else:
            hull = points

        return hull

ref_point = []
click = False
points =()
cap = cv.VideoCapture(0)
_, frame = cap.read()
old_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)

# # Update the lk_params
# lk_params = dict(winSize=(15, 15),
#                  maxLevel=3,    # Increase the number of pyramid levels
#                  criteria=(cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.03))

lk_params = dict(winSize=(20, 20),
                 maxLevel=4,
                 criteria=(cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.01))
  
cap = cv.VideoCapture(0)
point_selected = False
points = [()]
old_points = np.array([[]])
qr_detected= False
# stop_code=False

frame_counter =0
starting_time =time.time()
# keep looping until the 'q' key is pressed
while True:
    frame_counter +=1
    ret, frame = cap.read()
    width, height = frame.shape[1], frame.shape[0]
    square_width = width // 3
    square_height = height // 3

    for i in range(1, 3):
        cv.line(frame, (i * square_width, 0), (i * square_width, height), (255, 0, 0), 1)
        cv.line(frame, (0, i * square_height), (width, i * square_height), (255, 0, 0), 1)

    img = frame.copy()
    # img = cv.resize(img, None, fx=2, fy=2,interpolation=cv.INTER_CUBIC)
    cv.imshow('old frame ', old_gray)
    cv.imshow('img', img)

    gray_frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)
    # display the image and wait for a keypress
    clone = frame.copy()
    hull_points =detectQRcode(frame)
    # print(old_points.size)
    stop_code=False
    if hull_points:
        pt1, pt2, pt3, pt4 = hull_points
        qr_detected= True
        stop_code=True
        old_points = np.array([pt1, pt2, pt3, pt4], dtype=np.float32)
        # frame =AiPhile.fillPolyTrans(frame, hull_points, AiPhile.MAGENTA, 0.4)
        frame =fillPolyTrans(frame, hull_points, (255,0,255), 0.4)
        # AiPhile.textBGoutline(frame, f'Detection: Pyzbar', (30,80), scaling=0.5,text_color=((255,0,255)))
        # textBGoutline(frame, f'Detection: Pyzbar', (30,80), scaling=0.5,text_color=((255,0,255)))
        cv.circle(frame, pt1, 3, (0,255,0), 3)
        cv.circle(frame, pt2, 3, (255, 0, 0), 3)
        cv.circle(frame, pt3, 3,(0,255,255), 3)
        cv.circle(frame, pt4, 3, (0, 0, 255), 3)
                # Calculate QR diameter and center
        qr_diameter = max(np.linalg.norm(np.array(hull_points[0]) - np.array(hull_points[2])),np.linalg.norm(np.array(hull_points[1]) - np.array(hull_points[3])))
        qr_center_x = sum(point[0] for point in hull_points) // len(hull_points)
        qr_center_y = sum(point[1] for point in hull_points) // len(hull_points)

        # Display QR Diameter
        cv.putText(frame, f"Diameter: {qr_diameter}", (10, 90), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv.LINE_AA)

        # Middle coordinates of the frame
        middle_x, middle_y = width // 2, height // 2

        # Draw arrow from QR center to the middle of the grid
        cv.arrowedLine(frame, (qr_center_x, qr_center_y), (middle_x, middle_y), (0, 255, 255), 2)

        # Calculate the position of the QR code within the grid
        qr_position = ""
        if qr_center_x < square_width:
            if qr_center_y < square_height:
                qr_position = "Top Left"
            elif qr_center_y > 2 * square_height:
                qr_position = "Bottom Left"
            else:
                qr_position = "Left"
        elif qr_center_x > 2 * square_width:
            if qr_center_y < square_height:
                qr_position = "Top Right"
            elif qr_center_y > 2 * square_height:
                qr_position = "Bottom Right"
            else:
                qr_position = "Right"
        else:
            if qr_center_y < square_height:
                qr_position = "Top"
            elif qr_center_y > 2 * square_height:
                qr_position = "Bottom"
            else:
                qr_position = "Center"

        # Display the calculated QR position/direction
        cv.putText(frame, f"QR Position: {qr_position}", (10, 120), cv.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2, cv.LINE_AA)
        data_with_newline = qr_position + '\n'
        # arduino.write(data_with_newline.encode('utf-8'))
        qr_distance_from_center = np.sqrt((qr_center_x - middle_x) ** 2 + (qr_center_y - middle_y) ** 2)

        if qr_distance_from_center > 50:  # Adjust this threshold as needed
            # Implement speed calculation similar to the optical flow block
            speed, current_points = track_speed(old_gray, gray_frame, np.array([pt1, pt2, pt3, pt4], dtype=np.float32))
            if len(current_points) > 0:
                x, y, w, h = cv.boundingRect(current_points.astype(np.int32))
                cv.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
                cv.putText(frame, f'Speed: {speed:.2f} pixels/frame', (300, 300), cv.FONT_HERSHEY_SIMPLEX, 1,(0, 255, 0), 2, cv.LINE_AA)

    
        # time.sleep(0.1)

    if qr_detected and stop_code == False:
        new_points, status, error = cv.calcOpticalFlowPyrLK(old_gray, gray_frame, old_points, None, **lk_params)
        old_points = new_points
        new_points = new_points.astype(int)
        n = len(new_points)
        frame = fillPolyTrans(frame, new_points, (0, 255, 0), 0.4)
        # textBGoutline(frame, f'Detection: Optical Flow', (30, 80), scaling=0.5, text_color=(0, 255, 0))
        cv.circle(frame, (new_points[0]), 3, (0, 255, 0), 2)

        qr_diameter = max(np.linalg.norm(np.array(new_points[0]) - np.array(new_points[-1])),
                          np.linalg.norm(np.array(new_points[n // 2]) - np.array(new_points[n // 2 - 1])))
        qr_center_x = sum(point[0] for point in new_points) // len(new_points)
        qr_center_y = sum(point[1] for point in new_points) // len(new_points)

        cv.putText(frame, f"Diameter (Optical Flow): {qr_diameter}", (10, 150), cv.FONT_HERSHEY_SIMPLEX, 1,(0, 255, 0), 2, cv.LINE_AA)

        middle_x, middle_y = width // 2, height // 2
        cv.arrowedLine(frame, (qr_center_x, qr_center_y), (middle_x, middle_y), (0, 255, 255), 2)

        qr_position = ""
        if qr_center_x < square_width:
            if qr_center_y < square_height:
                qr_position = "Top Left"
            elif qr_center_y > 2 * square_height:
                qr_position = "Bottom Left"
            else:
                qr_position = "Left"
        elif qr_center_x > 2 * square_width:
            if qr_center_y < square_height:
                qr_position = "Top Right"
            elif qr_center_y > 2 * square_height:
                qr_position = "Bottom Right"
            else:
                qr_position = "Right"
        else:
            if qr_center_y < square_height:
                qr_position = "Top"
            elif qr_center_y > 2 * square_height:
                qr_position = "Bottom"
            else:
                qr_position = "Center"

        # cv.putText(frame, f"QR Position (Optical Flow): {qr_position}", (10, 180), cv.FONT_HERSHEY_SIMPLEX, 1,(255, 255, 0), 2, cv.LINE_AA)
        qr_distance_from_center = np.sqrt((qr_center_x - middle_x) ** 2 + (qr_center_y - middle_y) ** 2)

        if qr_distance_from_center > 50:  # Adjust this threshold as needed
            speed, current_points = track_speed(old_gray, gray_frame, old_points)
            if len(current_points) > 0:
                x, y, w, h = cv.boundingRect(current_points.astype(np.int32))
                cv.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
                cv.putText(frame, f'Speed: {speed:.2f} pixels/frame', (300, 300), cv.FONT_HERSHEY_SIMPLEX, 1,(0, 255, 0), 2, cv.LINE_AA)

    
        data_with_newline = qr_position + '\n'
        # arduino.write(data_with_newline.encode('utf-8'))
        time.sleep(0.1)

    old_gray = gray_frame.copy()
    # press 'r' to reset the window
    key = cv.waitKey(1)
    if key == ord("s"):
        cv.imwrite(f'reference_img/Ref_img{frame_counter}.png', img)

    # if the 'c' key is pressed, break from the loop
    if key == ord("q"):
        break
    fps = frame_counter/(time.time()-starting_time)
    # AiPhile.textBGoutline(frame, f'FPS: {round(fps,1)}', (30,40), scaling=0.6)
    # textBGoutline(frame, f'FPS: {round(fps,1)}', (30,40), scaling=0.6)
    cv.imshow("image", frame)

# close all open windows
cv.destroyAllWindows()
cap.release()